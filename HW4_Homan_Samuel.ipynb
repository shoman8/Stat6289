{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Github link:\n",
        "https://github.com/shoman8/Stat6289"
      ],
      "metadata": {
        "id": "XoG0iw6CGsdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/GoogleNews-vectors-negative300.magnitude'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVlMNwkUomVK",
        "outputId": "da7a9779-e2cb-4c44-8ab1-d311986cee6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Magnitude\n",
        "! echo \"Installing Magnitude.... (please wait, can take a while)\"\n",
        "! (curl https://raw.githubusercontent.com/plasticityai/magnitude/master/install-colab.sh | /bin/bash 1>/dev/null 2>/dev/null)\n",
        "! echo \"Done installing Magnitude.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APdTj9Ifoqjr",
        "outputId": "7fe228d5-f47d-4ee2-e2b0-09d7eff1cfd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Magnitude.... (please wait, can take a while)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   137  100   137    0     0   1223      0 --:--:-- --:--:-- --:--:--  1223\n",
            "Done installing Magnitude.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymagnitude import *\n",
        "vectors = Magnitude(data_path)"
      ],
      "metadata": {
        "id": "C1GFJZEG9JVS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Printing the number of dimensions in vectors, using the dim function, we see that the dimensionality of these word embeddings is 300."
      ],
      "metadata": {
        "id": "fNFpdBHFIvvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.) Dimensionality of word embeddings: 300\n",
        "print(vectors.dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rYh-YzBfiju",
        "outputId": "087e6a18-0f59-4588-a82a-3a2a1cb9a4a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\n",
        "Printing the 20 most similar words to picnic, using the most_similar function, we see that the 5 most similar words that don't contain \"picnic\" are:\n",
        "\n",
        "1.   cookout\n",
        "2.   Hiking_biking_camping\n",
        "3.   barbeque\n",
        "4.   barbecue\n",
        "5.   pig_roast\n",
        "\n",
        "These all make sense as these are activities and nouns that are complementary to the activiy of hiking."
      ],
      "metadata": {
        "id": "2GsFi7NOMjKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.) 5 most similar words to picnic\n",
        "top_20 = vectors.most_similar(\"picnic\", topn=20)"
      ],
      "metadata": {
        "id": "IZlikw6XfkJA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdIkeNOjsoXN",
        "outputId": "2f3f8b14-7015-4e65-d737-abda0ba12e1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('picnics', 0.7400875),\n",
              " ('picnic_lunch', 0.721374),\n",
              " ('Picnic', 0.700534),\n",
              " ('potluck_picnic', 0.6683274),\n",
              " ('picnic_supper', 0.65189123),\n",
              " ('picnicking', 0.63550216),\n",
              " ('cookout', 0.63243484),\n",
              " ('Hiking_biking_camping', 0.6256069),\n",
              " ('barbeque', 0.62256277),\n",
              " ('barbecue', 0.6195759),\n",
              " ('picnic_lunches', 0.6143184),\n",
              " ('pig_roast', 0.61019313),\n",
              " ('Bring_picnic', 0.6033048),\n",
              " ('potluck', 0.60114384),\n",
              " ('picnic_tables', 0.6006263),\n",
              " ('Hawaiian_luau', 0.5982951),\n",
              " ('wiener_roast', 0.59388626),\n",
              " ('potluck_dinner', 0.5916978),\n",
              " ('fish_fry', 0.58994764),\n",
              " ('gazebo', 0.58934724)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. \n",
        "Utilizing the doesnt_match function, we see that the word tissue is not like the rest of the list of papyrus, manila, newsprint, parchment, and gazette.  While tissue is also a paper product, the embedding may have trained on other uses of the word such as anatomical references."
      ],
      "metadata": {
        "id": "cPeOZr8oNiXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.) Which word is not like the others: ['tissue', 'papyrus', 'manila', 'newsprint', 'parchment', 'gazette']\n",
        "vectors.doesnt_match(['tissue', 'papyrus', 'manila', 'newsprint', 'parchment', 'gazette'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "z0pcDLDJgTBD",
        "outputId": "107f2a18-707a-4c31-982c-15ea348e77e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tissue'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.\n",
        "Solving the analogy using the most_similar function, we see that the best fit is the word forearm.  Thus, the analogy would be leg is to jump as forearm is to throw.  The lesser likely options are also anatomical references, but forearm makes the most sense as we do in fact throw with our arms."
      ],
      "metadata": {
        "id": "6JYqFsiMPDdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.) leg is to jump as X is to throw.  Find X\n",
        "vectors.most_similar(positive = [\"throw\", \"leg\"], negative = [\"jump\"]) # X=forearm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KVm-OwPgeZN",
        "outputId": "89e499c4-4b5d-4fd4-d4b4-67c59a94193f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('forearm', 0.48294652),\n",
              " ('shin', 0.47376165),\n",
              " ('elbow', 0.4679689),\n",
              " ('metacarpal_bone', 0.46781474),\n",
              " ('metacarpal_bones', 0.46605822),\n",
              " ('ankle', 0.46434426),\n",
              " ('shoulder', 0.46183354),\n",
              " ('thigh', 0.45393682),\n",
              " ('knee', 0.4455707),\n",
              " ('ulna_bone', 0.4423491)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}